{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1363a939-b0ec-4ca5-b04f-43415c80498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kornia pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a81c4b-fbde-4000-a771-4dd28f557b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in ./.local/lib/python3.9/site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from opencv-python) (1.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba3509ac-ebeb-4044-b5cc-2db65d0184f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: albumentations in ./.local/lib/python3.9/site-packages (1.1.0)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.9/site-packages (from albumentations) (1.7.3)\n",
      "Requirement already satisfied: PyYAML in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from albumentations) (5.4.1)\n",
      "Requirement already satisfied: qudida>=0.0.4 in ./.local/lib/python3.9/site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from albumentations) (1.20.3)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in ./.local/lib/python3.9/site-packages (from albumentations) (0.19.2)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in ./.local/lib/python3.9/site-packages (from albumentations) (4.5.5.64)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations) (4.1.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in ./.local/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Requirement already satisfied: networkx>=2.2 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2.5.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in ./.local/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2022.3.25)\n",
      "Requirement already satisfied: imageio>=2.4.1 in ./.local/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2.16.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in ./.local/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in ./.local/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (9.0.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from networkx>=2.2->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
      "Requirement already satisfied: joblib>=0.11 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.local/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef9f01f9-38bf-4c1b-a2ae-ffee9d25d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentations\n",
    "import random\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "from kornia import augmentation as aug\n",
    "from kornia import filters\n",
    "from kornia.geometry import transform as tf\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "class RandomApply(nn.Module):\n",
    "    def __init__(self, fn: Callable, p: float):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return x if random.random() > self.p else self.fn(x)\n",
    "\n",
    "\n",
    "def default_augmentation(image_size: Tuple[int, int] = (224, 224)) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        tf.Resize(size=image_size),\n",
    "        RandomApply(aug.ColorJitter(0.8, 0.8, 0.8, 0.2), p=0.8),\n",
    "        aug.RandomGrayscale(p=0.2),\n",
    "        aug.RandomHorizontalFlip(),\n",
    "        RandomApply(filters.GaussianBlur2d((3, 3), (1.5, 1.5)), p=0.1),\n",
    "        aug.RandomResizedCrop(size=image_size),\n",
    "        aug.Normalize(\n",
    "            mean=torch.tensor([0.485, 0.456, 0.406]),\n",
    "            std=torch.tensor([0.229, 0.224, 0.225]),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e51994-067e-493e-aafe-99d78754b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "def mlp(dim: int, projection_size: int = 256, hidden_size: int = 4096) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim, hidden_size),\n",
    "        nn.BatchNorm1d(hidden_size),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(hidden_size, projection_size),\n",
    "    )\n",
    "\n",
    "\n",
    "class EncoderWrapper(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        projection_size: int = 256,\n",
    "        hidden_size: int = 4096,\n",
    "        layer: Union[str, int] = -2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.projection_size = projection_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer = layer\n",
    "\n",
    "        self._projector = None\n",
    "        self._projector_dim = None\n",
    "        self._encoded = torch.empty(0)\n",
    "        self._register_hook()\n",
    "\n",
    "    @property\n",
    "    def projector(self):\n",
    "        if self._projector is None:\n",
    "            self._projector = mlp(\n",
    "                self._projector_dim, self.projection_size, self.hidden_size\n",
    "            )\n",
    "        return self._projector\n",
    "\n",
    "    def _hook(self, _, __, output):\n",
    "        output = output.flatten(start_dim=1)\n",
    "        if self._projector_dim is None:\n",
    "            self._projector_dim = output.shape[-1]\n",
    "        self._encoded = self.projector(output)\n",
    "\n",
    "    def _register_hook(self):\n",
    "        if isinstance(self.layer, str):\n",
    "            layer = dict([*self.model.named_modules()])[self.layer]\n",
    "        else:\n",
    "            layer = list(self.model.children())[self.layer]\n",
    "\n",
    "        layer.register_forward_hook(self._hook)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        _ = self.model(x)\n",
    "        return self._encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c40882e3-9a0c-47d0-9c4f-0f36c4c30dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#byol training\n",
    "from copy import deepcopy\n",
    "from itertools import chain\n",
    "from typing import Dict, List\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torch import optim\n",
    "import torch.nn.functional as f\n",
    "from torchvision.datasets import STL10\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from os import cpu_count\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "\n",
    "\n",
    "def normalized_mse(x: Tensor, y: Tensor) -> Tensor:\n",
    "    x = f.normalize(x, dim=-1)\n",
    "    y = f.normalize(y, dim=-1)\n",
    "    return 2 - 2 * (x * y).sum(dim=-1)\n",
    "\n",
    "\n",
    "class BYOL(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        image_size: Tuple[int, int] = (128, 128),\n",
    "        hidden_layer: Union[str, int] = -2,\n",
    "        projection_size: int = 256,\n",
    "        hidden_size: int = 4096,\n",
    "        augment_fn: Callable = None,\n",
    "        beta: float = 0.999,\n",
    "        **hparams,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.augment = default_augmentation(image_size) if augment_fn is None else augment_fn\n",
    "        self.beta = beta\n",
    "        self.encoder = EncoderWrapper(\n",
    "            model, projection_size, hidden_size, layer=hidden_layer\n",
    "        )\n",
    "        self.predictor = nn.Linear(projection_size, projection_size, hidden_size)\n",
    "        self.hparams.update(hparams)\n",
    "        self._target = None\n",
    "\n",
    "        self.encoder(torch.zeros(2, 3, *image_size))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.predictor(self.encoder(x))\n",
    "\n",
    "    @property\n",
    "    def target(self):\n",
    "        if self._target is None:\n",
    "            self._target = deepcopy(self.encoder)\n",
    "        return self._target\n",
    "\n",
    "    def update_target(self):\n",
    "        for p, pt in zip(self.encoder.parameters(), self.target.parameters()):\n",
    "            pt.data = self.beta * pt.data + (1 - self.beta) * p.data\n",
    "\n",
    "    # --- Methods required for PyTorch Lightning only! ---\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = getattr(optim, self.hparams.get(\"optimizer\", \"Adam\"))\n",
    "        lr = self.hparams.get(\"lr\", 1e-4)\n",
    "        weight_decay = self.hparams.get(\"weight_decay\", 1e-6)\n",
    "        return optimizer(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    def training_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x = batch[0]\n",
    "        with torch.no_grad():\n",
    "            x1, x2 = self.augment(x), self.augment(x)\n",
    "\n",
    "        pred1, pred2 = self.forward(x1), self.forward(x2)\n",
    "        with torch.no_grad():\n",
    "            targ1, targ2 = self.target(x1), self.target(x2)\n",
    "        loss = torch.mean(normalized_mse(pred1, targ2) + normalized_mse(pred2, targ1))\n",
    "\n",
    "        self.log(\"train_loss\", loss.item())\n",
    "        self.update_target()\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x = batch[0]\n",
    "        x1, x2 = self.augment(x), self.augment(x)\n",
    "        pred1, pred2 = self.forward(x1), self.forward(x2)\n",
    "        targ1, targ2 = self.target(x1), self.target(x2)\n",
    "        loss = torch.mean(normalized_mse(pred1, targ2) + normalized_mse(pred2, targ1))\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_epoch_end(self, outputs: List[Dict]) -> Dict:\n",
    "        val_loss = sum(x[\"loss\"] for x in outputs) / len(outputs)\n",
    "        self.log(\"val_loss\", val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a58a75da-50d2-4a16-8fe2-c44ed091db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedLightningModule(pl.LightningModule):\n",
    "    def __init__(self, model: nn.Module, **hparams):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = getattr(optim, self.hparams.get(\"optimizer\", \"Adam\"))\n",
    "        lr = self.hparams.get(\"lr\", 1e-4)\n",
    "        weight_decay = self.hparams.get(\"weight_decay\", 1e-6)\n",
    "        return optimizer(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    def training_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x, y = batch\n",
    "        loss = f.cross_entropy(self.forward(x), y)\n",
    "        self.log(\"train_loss\", loss.item())\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x, y = batch\n",
    "        loss = f.cross_entropy(self.forward(x), y)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_epoch_end(self, outputs: List[Dict]) -> Dict:\n",
    "        val_loss = sum(x[\"loss\"] for x in outputs) / len(outputs)\n",
    "        self.log(\"val_loss\", val_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1e396b2-4673-4281-8031-43652aaf004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e7a037-b75e-4d88-8d0d-efa7be4fbf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelanomaDataset(Dataset):\n",
    "    def __init__(self, csv, mode, meta_features, transform=None):\n",
    "\n",
    "        self.csv = csv.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        self.use_meta = meta_features is not None\n",
    "        self.meta_features = meta_features\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        row = self.csv.iloc[index]\n",
    "\n",
    "        image = cv2.imread(row.filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = image.astype(np.float32)\n",
    "        \n",
    "        image = image.transpose(2, 0, 1)\n",
    "\n",
    "        data = torch.tensor(image).float()\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return data\n",
    "        else:\n",
    "            return data, torch.tensor(self.csv.iloc[index].target).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d50982f0-25a0-42f5-992f-d170e2e52b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '1024'\n",
    "data_dir = '/blue/daisyw/iharmon1/data/SIIM-ISIC/data/'\n",
    "# 2020 data\n",
    "df_train = pd.read_csv(os.path.join(data_dir, f'jpeg-melanoma-{data_folder}x{data_folder}', 'train.csv'))\n",
    "df_train = df_train[df_train['tfrecord'] != -1].reset_index(drop=True)\n",
    "df_train['filepath'] = df_train['image_name'].apply(lambda x: os.path.join(data_dir, f'jpeg-melanoma-{data_folder}x{data_folder}/train', f'{x}.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "795c898b-e325-4660-8d35-86d149349a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "      <th>tfrecord</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>nevus</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1872</td>\n",
       "      <td>1053</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1872</td>\n",
       "      <td>1053</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32687</th>\n",
       "      <td>ISIC_9999134</td>\n",
       "      <td>IP_6526534</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2592</td>\n",
       "      <td>1936</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32688</th>\n",
       "      <td>ISIC_9999320</td>\n",
       "      <td>IP_3650745</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32689</th>\n",
       "      <td>ISIC_9999515</td>\n",
       "      <td>IP_2026598</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1872</td>\n",
       "      <td>1053</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32690</th>\n",
       "      <td>ISIC_9999666</td>\n",
       "      <td>IP_7702038</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1872</td>\n",
       "      <td>1053</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32691</th>\n",
       "      <td>ISIC_9999806</td>\n",
       "      <td>IP_0046310</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>nevus</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1872</td>\n",
       "      <td>1053</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32692 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name  patient_id     sex  age_approx  \\\n",
       "0      ISIC_2637011  IP_7279968    male        45.0   \n",
       "1      ISIC_0015719  IP_3075186  female        45.0   \n",
       "2      ISIC_0052212  IP_2842074  female        50.0   \n",
       "3      ISIC_0068279  IP_6890425  female        45.0   \n",
       "4      ISIC_0074268  IP_8723313  female        55.0   \n",
       "...             ...         ...     ...         ...   \n",
       "32687  ISIC_9999134  IP_6526534    male        50.0   \n",
       "32688  ISIC_9999320  IP_3650745    male        65.0   \n",
       "32689  ISIC_9999515  IP_2026598    male        20.0   \n",
       "32690  ISIC_9999666  IP_7702038    male        50.0   \n",
       "32691  ISIC_9999806  IP_0046310    male        45.0   \n",
       "\n",
       "      anatom_site_general_challenge diagnosis benign_malignant  target  \\\n",
       "0                         head/neck   unknown           benign       0   \n",
       "1                   upper extremity   unknown           benign       0   \n",
       "2                   lower extremity     nevus           benign       0   \n",
       "3                         head/neck   unknown           benign       0   \n",
       "4                   upper extremity   unknown           benign       0   \n",
       "...                             ...       ...              ...     ...   \n",
       "32687                         torso   unknown           benign       0   \n",
       "32688                         torso   unknown           benign       0   \n",
       "32689               lower extremity   unknown           benign       0   \n",
       "32690               lower extremity   unknown           benign       0   \n",
       "32691                         torso     nevus           benign       0   \n",
       "\n",
       "       tfrecord  width  height  \\\n",
       "0             0   6000    4000   \n",
       "1             0   6000    4000   \n",
       "2             6   1872    1053   \n",
       "3             0   1872    1053   \n",
       "4            11   6000    4000   \n",
       "...         ...    ...     ...   \n",
       "32687         2   2592    1936   \n",
       "32688        11   6000    4000   \n",
       "32689         3   1872    1053   \n",
       "32690        11   1872    1053   \n",
       "32691         4   1872    1053   \n",
       "\n",
       "                                                filepath  \n",
       "0      /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "1      /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "2      /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "3      /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "4      /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "...                                                  ...  \n",
       "32687  /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "32688  /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "32689  /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "32690  /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "32691  /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "\n",
       "[32692 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9191cba7-05f4-47d2-807b-9db6780bd1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET = MelanomaDataset(df_train,mode='train',meta_features = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73f2c0ab-57b0-4686-9d78-a8bb2cccfc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32692"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(TRAIN_DATASET)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56a03dd8-d075-4dbc-8024-856f9f3be9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(TRAIN_DATASET, [int(total*0.9), total-int(total*0.9)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6b524f0-d67e-453a-9298-769dba6c14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fba7ac7f-2f3e-4565-b4a2-c9b92716194b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ce804a0-99e4-4d4d-b3e7-7cfe2ab1218b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocessing is handled by SLURM.\n",
      "/home/sanjanar.guttalu/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:171: LightningDeprecationWarning: Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed in v1.7. Please set `Trainer(enable_model_summary=False)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,7]\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d7634b8486460293ca53f9559e8d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanjanar.guttalu/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 256 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/sanjanar.guttalu/.local/lib/python3.9/site-packages/torch/nn/functional.py:3609: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n",
      "/home/sanjanar.guttalu/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 256 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983d6993c00746fe964cb99f41ae3324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d780aedb4ed84332a7bc1d97e6707430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eeb93fb815541f69431942b506f3ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43aa6d2e611c429390539d3a1ae67f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b6c9e9a2794d5697d8cccb7b05d7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705ba2f0dd4746708d8baaa7d5b12e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Self-Supervision\n",
    "\n",
    "byol = BYOL(model, image_size=(96, 96))\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5, \n",
    "    gpus=1,\n",
    "    accumulate_grad_batches=2048 // 128,\n",
    "    weights_summary=None,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=2\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=128,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "trainer.fit(byol, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96ae49f0-0dc0-4b7d-86dd-c52f0e9acbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocessing is handled by SLURM.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/sanjanar.guttalu/.local/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:608: UserWarning: Checkpoint directory /home/sanjanar.guttalu/lightning_logs/version_24480657/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,7]\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669b8c8171e540f8a2ee3190e0939b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0706407ac9143139f618deec16fee0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c8425da71f410a9334d452dfbd9fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b7c6392beb448b9e417894cd26d65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95569f729fb84977a37ac218b26a7c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd34fdc90df04b5db8a72d5eb7404b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2d3696f0344349a0475046642fbe56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled = False \n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "##Supervision\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "state_dict = model.state_dict()\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "supervised = SupervisedLightningModule(model)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5, \n",
    "    gpus=1,\n",
    "    weights_summary=None,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=25,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=2\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=25,\n",
    "    num_workers=2\n",
    ")\n",
    "trainer.fit(supervised, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fe42aaa-c52b-4bd3-808f-aa6fffb3fdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "def accuracy(pred: Tensor, labels: Tensor) -> float:\n",
    "    return (pred.argmax(dim=-1) == labels).float().mean().item()\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "acc = sum([accuracy(model(x.cuda()), y.cuda()) for x, y in val_loader]) / len(val_loader)\n",
    "print(f\"Accuracy: {acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8.1",
   "language": "python",
   "name": "pytorch-1.8.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
