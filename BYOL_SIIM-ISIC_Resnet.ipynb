{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d675f891-2ee4-48c5-a4e7-44af964f0f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kornia pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cca253b-9936-48f3-a49d-309bbf8d56da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.5 MB 157 kB/s eta 0:00:01                    | 8.4 MB 3.3 MB/s eta 0:00:16 MB 3.3 MB/s eta 0:00:14��        | 45.2 MB 3.3 MB/s eta 0:00:05\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from opencv-python) (1.20.3)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.64\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "575a0e01-0462-4deb-8b38-15f265a36d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\n",
      "\u001b[K     |████████████████████████████████| 102 kB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from albumentations) (1.6.3)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 47.8 MB 13.9 MB/s eta 0:00:01��███████████████████▏   | 42.1 MB 13.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-image>=0.16.1\n",
      "  Downloading scikit_image-0.19.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.0 MB 27.7 MB/s eta 0:00:01   | 4.1 MB 27.7 MB/s eta 0:00:01�██████▎          | 9.3 MB 27.7 MB/s eta 0:00:01/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from albumentations) (1.20.3)\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: PyYAML in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from albumentations) (5.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations) (0.24.2)\n",
      "Requirement already satisfied: typing-extensions in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations) (3.10.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (8.2.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2.5.1)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2022.3.25-py3-none-any.whl (179 kB)\n",
      "\u001b[K     |████████████████████████████████| 179 kB 127.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9 MB 29.5 MB/s eta 0:00:01�█████████████████▌         | 4.9 MB 29.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio>=2.4.1\n",
      "  Downloading imageio-2.16.1-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 126.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0\n",
      "  Downloading Pillow-9.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 120.3 MB/s eta 0:00:01            | 1.1 MB 120.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator<5,>=4.3 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from networkx>=2.2->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
      "Requirement already satisfied: joblib>=0.11 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /apps/pytorch/1.8.1/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (2.1.0)\n",
      "Installing collected packages: pillow, tifffile, PyWavelets, opencv-python-headless, imageio, scikit-image, qudida, albumentations\n",
      "Successfully installed PyWavelets-1.3.0 albumentations-1.1.0 imageio-2.16.1 opencv-python-headless-4.5.5.64 pillow-9.0.1 qudida-0.0.4 scikit-image-0.19.2 tifffile-2022.3.25\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3dbcf5-0abd-409a-be5a-88e34ed53483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentations\n",
    "import random\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "from kornia import augmentation as aug\n",
    "from kornia import filters\n",
    "from kornia.geometry import transform as tf\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "class RandomApply(nn.Module):\n",
    "    def __init__(self, fn: Callable, p: float):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return x if random.random() > self.p else self.fn(x)\n",
    "\n",
    "\n",
    "def default_augmentation(image_size: Tuple[int, int] = (224, 224)) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        tf.Resize(size=image_size),\n",
    "        RandomApply(aug.ColorJitter(0.8, 0.8, 0.8, 0.2), p=0.8),\n",
    "        aug.RandomGrayscale(p=0.2),\n",
    "        aug.RandomHorizontalFlip(),\n",
    "        RandomApply(filters.GaussianBlur2d((3, 3), (1.5, 1.5)), p=0.1),\n",
    "        aug.RandomResizedCrop(size=image_size),\n",
    "        aug.Normalize(\n",
    "            mean=torch.tensor([0.485, 0.456, 0.406]),\n",
    "            std=torch.tensor([0.229, 0.224, 0.225]),\n",
    "        ),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b11cb9-b916-40b4-8381-750dbdd56903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "def mlp(dim: int, projection_size: int = 256, hidden_size: int = 4096) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim, hidden_size),\n",
    "        nn.BatchNorm1d(hidden_size),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(hidden_size, projection_size),\n",
    "    )\n",
    "\n",
    "\n",
    "class EncoderWrapper(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        projection_size: int = 256,\n",
    "        hidden_size: int = 4096,\n",
    "        layer: Union[str, int] = -2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.projection_size = projection_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer = layer\n",
    "\n",
    "        self._projector = None\n",
    "        self._projector_dim = None\n",
    "        self._encoded = torch.empty(0)\n",
    "        self._register_hook()\n",
    "\n",
    "    @property\n",
    "    def projector(self):\n",
    "        if self._projector is None:\n",
    "            self._projector = mlp(\n",
    "                self._projector_dim, self.projection_size, self.hidden_size\n",
    "            )\n",
    "        return self._projector\n",
    "\n",
    "    def _hook(self, _, __, output):\n",
    "        output = output.flatten(start_dim=1)\n",
    "        if self._projector_dim is None:\n",
    "            self._projector_dim = output.shape[-1]\n",
    "        self._encoded = self.projector(output)\n",
    "\n",
    "    def _register_hook(self):\n",
    "        if isinstance(self.layer, str):\n",
    "            layer = dict([*self.model.named_modules()])[self.layer]\n",
    "        else:\n",
    "            layer = list(self.model.children())[self.layer]\n",
    "\n",
    "        layer.register_forward_hook(self._hook)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        _ = self.model(x)\n",
    "        return self._encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7390c5a0-f9e3-4cad-86ec-7e08113176bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#byol training\n",
    "from copy import deepcopy\n",
    "from itertools import chain\n",
    "from typing import Dict, List\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torch import optim\n",
    "import torch.nn.functional as f\n",
    "from torchvision.datasets import STL10\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from os import cpu_count\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "\n",
    "\n",
    "def normalized_mse(x: Tensor, y: Tensor) -> Tensor:\n",
    "    x = f.normalize(x, dim=-1)\n",
    "    y = f.normalize(y, dim=-1)\n",
    "    return 2 - 2 * (x * y).sum(dim=-1)\n",
    "\n",
    "\n",
    "class BYOL(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        image_size: Tuple[int, int] = (128, 128),\n",
    "        hidden_layer: Union[str, int] = -2,\n",
    "        projection_size: int = 256,\n",
    "        hidden_size: int = 4096,\n",
    "        augment_fn: Callable = None,\n",
    "        beta: float = 0.999,\n",
    "        **hparams,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.augment = default_augmentation(image_size) if augment_fn is None else augment_fn\n",
    "        self.beta = beta\n",
    "        self.encoder = EncoderWrapper(\n",
    "            model, projection_size, hidden_size, layer=hidden_layer\n",
    "        )\n",
    "        self.predictor = nn.Linear(projection_size, projection_size, hidden_size)\n",
    "        self.hparams.update(hparams)\n",
    "        self._target = None\n",
    "\n",
    "        self.encoder(torch.zeros(2, 3, *image_size))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.predictor(self.encoder(x))\n",
    "\n",
    "    @property\n",
    "    def target(self):\n",
    "        if self._target is None:\n",
    "            self._target = deepcopy(self.encoder)\n",
    "        return self._target\n",
    "\n",
    "    def update_target(self):\n",
    "        for p, pt in zip(self.encoder.parameters(), self.target.parameters()):\n",
    "            pt.data = self.beta * pt.data + (1 - self.beta) * p.data\n",
    "\n",
    "    # --- Methods required for PyTorch Lightning only! ---\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = getattr(optim, self.hparams.get(\"optimizer\", \"Adam\"))\n",
    "        lr = self.hparams.get(\"lr\", 1e-4)\n",
    "        weight_decay = self.hparams.get(\"weight_decay\", 1e-6)\n",
    "        return optimizer(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    def training_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x = batch[0]\n",
    "        with torch.no_grad():\n",
    "            x1, x2 = self.augment(x), self.augment(x)\n",
    "\n",
    "        pred1, pred2 = self.forward(x1), self.forward(x2)\n",
    "        with torch.no_grad():\n",
    "            targ1, targ2 = self.target(x1), self.target(x2)\n",
    "        loss = torch.mean(normalized_mse(pred1, targ2) + normalized_mse(pred2, targ1))\n",
    "\n",
    "        self.log(\"train_loss\", loss.item())\n",
    "        self.update_target()\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x = batch[0]\n",
    "        x1, x2 = self.augment(x), self.augment(x)\n",
    "        pred1, pred2 = self.forward(x1), self.forward(x2)\n",
    "        targ1, targ2 = self.target(x1), self.target(x2)\n",
    "        loss = torch.mean(normalized_mse(pred1, targ2) + normalized_mse(pred2, targ1))\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_epoch_end(self, outputs: List[Dict]) -> Dict:\n",
    "        val_loss = sum(x[\"loss\"] for x in outputs) / len(outputs)\n",
    "        self.log(\"val_loss\", val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5c53469-70b3-4b2c-a7e9-72f20d92afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedLightningModule(pl.LightningModule):\n",
    "    def __init__(self, model: nn.Module, **hparams):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = getattr(optim, self.hparams.get(\"optimizer\", \"Adam\"))\n",
    "        lr = self.hparams.get(\"lr\", 1e-4)\n",
    "        weight_decay = self.hparams.get(\"weight_decay\", 1e-6)\n",
    "        return optimizer(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    def training_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x, y = batch\n",
    "        loss = f.cross_entropy(self.forward(x), y)\n",
    "        self.log(\"train_loss\", loss.item())\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x, y = batch\n",
    "        loss = f.cross_entropy(self.forward(x), y)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_epoch_end(self, outputs: List[Dict]) -> Dict:\n",
    "        val_loss = sum(x[\"loss\"] for x in outputs) / len(outputs)\n",
    "        self.log(\"val_loss\", val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea77a5c-a622-4ffa-9bd4-b6d181fd5a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9643db3-f523-4209-92db-7a0ec1d29d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelanomaDataset(Dataset):\n",
    "    def __init__(self, csv, mode, meta_features, transform=None):\n",
    "\n",
    "        self.csv = csv.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        self.use_meta = meta_features is not None\n",
    "        self.meta_features = meta_features\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        row = self.csv.iloc[index]\n",
    "\n",
    "        image = cv2.imread(row.filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = image.astype(np.float32)\n",
    "        \n",
    "        image = image.transpose(2, 0, 1)\n",
    "\n",
    "        data = torch.tensor(image).float()\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return data\n",
    "        else:\n",
    "            return data, torch.tensor(self.csv.iloc[index].target).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "512da97c-0201-445b-b62c-4084d84b2cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '1024'\n",
    "data_dir = '/blue/daisyw/iharmon1/data/SIIM-ISIC/data/'\n",
    "# 2020 data\n",
    "df_train = pd.read_csv(os.path.join(data_dir, f'jpeg-melanoma-{data_folder}x{data_folder}', 'train.csv'))\n",
    "df_train = df_train[df_train['tfrecord'] != -1].reset_index(drop=True)\n",
    "df_train['filepath'] = df_train['image_name'].apply(lambda x: os.path.join(data_dir, f'jpeg-melanoma-{data_folder}x{data_folder}/train', f'{x}.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b352b61-dab6-43a2-afc5-188451ba2d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "      <th>tfrecord</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>nevus</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1872</td>\n",
       "      <td>1053</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1872</td>\n",
       "      <td>1053</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32687</th>\n",
       "      <td>ISIC_9999134</td>\n",
       "      <td>IP_6526534</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2592</td>\n",
       "      <td>1936</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32688</th>\n",
       "      <td>ISIC_9999320</td>\n",
       "      <td>IP_3650745</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32689</th>\n",
       "      <td>ISIC_9999515</td>\n",
       "      <td>IP_2026598</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1872</td>\n",
       "      <td>1053</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32690</th>\n",
       "      <td>ISIC_9999666</td>\n",
       "      <td>IP_7702038</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1872</td>\n",
       "      <td>1053</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32691</th>\n",
       "      <td>ISIC_9999806</td>\n",
       "      <td>IP_0046310</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>nevus</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1872</td>\n",
       "      <td>1053</td>\n",
       "      <td>/blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32692 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name  patient_id     sex  age_approx  \\\n",
       "0      ISIC_2637011  IP_7279968    male        45.0   \n",
       "1      ISIC_0015719  IP_3075186  female        45.0   \n",
       "2      ISIC_0052212  IP_2842074  female        50.0   \n",
       "3      ISIC_0068279  IP_6890425  female        45.0   \n",
       "4      ISIC_0074268  IP_8723313  female        55.0   \n",
       "...             ...         ...     ...         ...   \n",
       "32687  ISIC_9999134  IP_6526534    male        50.0   \n",
       "32688  ISIC_9999320  IP_3650745    male        65.0   \n",
       "32689  ISIC_9999515  IP_2026598    male        20.0   \n",
       "32690  ISIC_9999666  IP_7702038    male        50.0   \n",
       "32691  ISIC_9999806  IP_0046310    male        45.0   \n",
       "\n",
       "      anatom_site_general_challenge diagnosis benign_malignant  target  \\\n",
       "0                         head/neck   unknown           benign       0   \n",
       "1                   upper extremity   unknown           benign       0   \n",
       "2                   lower extremity     nevus           benign       0   \n",
       "3                         head/neck   unknown           benign       0   \n",
       "4                   upper extremity   unknown           benign       0   \n",
       "...                             ...       ...              ...     ...   \n",
       "32687                         torso   unknown           benign       0   \n",
       "32688                         torso   unknown           benign       0   \n",
       "32689               lower extremity   unknown           benign       0   \n",
       "32690               lower extremity   unknown           benign       0   \n",
       "32691                         torso     nevus           benign       0   \n",
       "\n",
       "       tfrecord  width  height  \\\n",
       "0             0   6000    4000   \n",
       "1             0   6000    4000   \n",
       "2             6   1872    1053   \n",
       "3             0   1872    1053   \n",
       "4            11   6000    4000   \n",
       "...         ...    ...     ...   \n",
       "32687         2   2592    1936   \n",
       "32688        11   6000    4000   \n",
       "32689         3   1872    1053   \n",
       "32690        11   1872    1053   \n",
       "32691         4   1872    1053   \n",
       "\n",
       "                                                filepath  \n",
       "0      /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "1      /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "2      /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "3      /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "4      /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "...                                                  ...  \n",
       "32687  /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "32688  /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "32689  /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "32690  /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "32691  /blue/daisyw/iharmon1/data/SIIM-ISIC/data/jpeg...  \n",
       "\n",
       "[32692 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "373a80e4-fc12-4324-8d5f-808ff3b2333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET = MelanomaDataset(df_train,mode='train',meta_features = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "874be3a1-97e6-48ca-99b5-7e620019006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68275dcb-d380-45e1-b834-a58cfab1c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(TRAIN_DATASET, [int(total*0.9), total-int(total*0.9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6cfd17f-0993-40eb-af05-419d70efeb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/apps/pytorch/1.8.1/lib/python3.9/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [6]\n",
      "Set SLURM handle signals.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3894a6f3b4841f49f44c70a3ad953ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Self-Supervision\n",
    "\n",
    "model = resnet18(pretrained=True)\n",
    "byol = BYOL(model, image_size=(96, 96))\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50, \n",
    "    gpus=1,\n",
    "    accumulate_grad_batches=2048 // 128,\n",
    "    weights_summary=None,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=2\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=128,\n",
    "    num_workers=2\n",
    ")\n",
    "trainer.fit(byol, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "284dc207-8fea-4ae8-8c8c-4ac9e8dbd3e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Supervision\n",
    "\n",
    "state_dict = model.state_dict()\n",
    "model = resnet18()\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "supervised = SupervisedLightningModule(model)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=25, \n",
    "    gpus=1,\n",
    "    weights_summary=None,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=2\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=128,\n",
    "    num_workers=2\n",
    ")\n",
    "trainer.fit(supervised, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2460b289-6f57-4c9a-b2df-9bcaae558f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred: Tensor, labels: Tensor) -> float:\n",
    "    return (pred.argmax(dim=-1) == labels).float().mean().item()\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "acc = sum([accuracy(model(x.cuda()), y.cuda()) for x, y in val_loader]) / len(val_loader)\n",
    "print(f\"Accuracy: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1da5a58-05d8-497b-b948-52b23663a186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8.1",
   "language": "python",
   "name": "pytorch-1.8.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
